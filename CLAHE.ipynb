{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CLAHE experiments**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importing Libraries**\n",
    "\n",
    "In this paragraph, we have imported the necessary libraries to create the CNN. TensorFlow and Keras are the main frameworks that we will use to create the convolutional neural network. Additionally, we have imported other useful libraries such as OpenCV (cv2) for image preprocessing, PIL for image manipulation, and Matplotlib for image visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Activation,Concatenate, BatchNormalization\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from sklearn.utils import shuffle\n",
    "import zipfile\n",
    "import cv2\n",
    "import imutils\n",
    "from google.colab.patches import cv2_imshow\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Google Drive connection**\n",
    "\n",
    "Necessary to run the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Utilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4520 images belonging to 4 classes.\n",
      "Found 652 images belonging to 4 classes.\n",
      "Found 652 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,roc_curve, auc, roc_auc_score\n",
    "\n",
    "dataset_path = \"/content/drive/MyDrive/BrainTumorDataset\"\n",
    "\n",
    "# Percorso della cartella \"unified\" che contiene le sottocartelle delle classi\n",
    "base_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Unified\"\n",
    "\n",
    "# Definisci i percorsi per il set di test, di validazione e di addestramento\n",
    "test_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Test\"\n",
    "val_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Validation\"\n",
    "train_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Train\"\n",
    "\n",
    "def set_seed ():\n",
    "\t''' \n",
    "\tset_seed is used to obtain reproducible results using keras during the development phase\n",
    "\t'''\n",
    "\tseed = 10\n",
    "\t# The below is necessary for reproducible results of certain Python hash-based operations.\n",
    "\tos.environ[\"PYTHONHASHSEED\"]=\"0\"\n",
    "\t# The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "\tnp.random.seed(seed)\n",
    "\t# The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "\trn.seed(seed)\n",
    "\t# The below tf.random.set_seed will make x number generation in TensorFlow have a well-defined initial state.\n",
    "\ttf.random.set_seed(seed)     \n",
    "\n",
    "# Definisci le dimensioni delle immagini\n",
    "image_size = 250\n",
    "batch_size = 32\n",
    "\n",
    "# Crea un oggetto ImageDataGenerator per il preprocessing delle immagini\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Carica le immagini dal set di addestramento\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Carica le immagini dal set di test\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Carica le immagini dal set di validazione\n",
    "val_generator = data_generator.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "     \n",
    "\n",
    "def show_training_and_validation_performance(history):\n",
    "\t'''\n",
    "\tshow_training_and_validation_performance is used to plot the performances during the training phase\n",
    "\t:param history: object in which are recorded all the events\n",
    "\t'''\n",
    "\tacc = history.history['accuracy']\n",
    "\tval_acc = history.history['val_accuracy']\n",
    "\tloss = history.history['loss']\n",
    "\tval_loss = history.history['val_loss']\n",
    "\n",
    "\tepochs = range(len(acc))\n",
    "\n",
    "\tplt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "\tplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "\tplt.title('Training and validation accuracy')\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.figure()\n",
    "\n",
    "\tplt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "\tplt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "\tplt.title('Training and validation loss')\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.show()\n",
    "\n",
    "def compile_model (model, optimizer='adam', learning_rate = 0.001):\n",
    "\t'''\n",
    "\tcompile_model is used to compile the current model\n",
    "\t:param model: model to compile\n",
    "\t:param optimizer: optimizer to be used\n",
    "\t:param learning_rate: learning rate parameter for the optimizer\n",
    "\t'''\n",
    "\tif optimizer == 'adam':\n",
    "\t\tmodel.compile(loss=\"categorical_crossentropy\",\n",
    "\t\toptimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "\t\tmetrics=[\"accuracy\"])\n",
    "\telif optimizer == 'rmsprop':\n",
    "\t\tmodel.compile(loss=\"categorical_crossentropy\",\n",
    "\t\t\t\t\toptimizer = optimizers.RMSprop(learning_rate=learning_rate),\n",
    "\t\t\t\t\tmetrics=['accuracy'])\n",
    "\tmodel.summary()\n",
    "\n",
    "def run_model (model, model_name, epochs = 100, patience=5, monitor='val_loss'):\n",
    "\t'''\n",
    "\trun_model is used to run the current mode\n",
    "\t:param model: model to run\n",
    "\t:param model_name: name given to save the model\n",
    "\t:param epochs: how many epochs to do\n",
    "\t:param patience: patience value for Early Stopping\n",
    "\t:param monitor: what to monitor for Early Stopping and Model Checkpoint\n",
    "\t'''\n",
    "\t# local save path for the models\n",
    "\tsave_path = dataset_path + '/' + model_name + '.h5'\n",
    "\tcallbacks_list = [\n",
    "\t\t\t\t\tkeras.callbacks.EarlyStopping(monitor=monitor, patience=patience),\n",
    "\t\t\t\t\tkeras.callbacks.ModelCheckpoint(\n",
    "\t\t\t\t\t\tfilepath = save_path,\n",
    "\t\t\t\t\t\tmonitor=monitor,\n",
    "\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\tsave_best_only=True)\n",
    "\t\t\t\t\t]\n",
    "\thistory = model.fit(train_generator,\n",
    "\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\tvalidation_data=val_generator,\n",
    "\t\t\t\t\t\tcallbacks=callbacks_list)\n",
    "\t# save on Drive only the best model\n",
    "\tshow_training_and_validation_performance(history)\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred, n_classes, class_labels):\n",
    "\n",
    "    # Converti le etichette di classe in formato binario\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_binary = lb.fit_transform(y_true)\n",
    "\n",
    "    # Calcola i tassi di FPR e TPR per ogni classe\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = metrics.roc_curve(y_true_binary[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "    plt.figure()\n",
    "    colors = ['blue', 'red', 'green', 'orange']  # Colori per le diverse classi\n",
    "\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, label='ROC curve {0} ({1:0.2f}%)'.format(class_labels[i], roc_auc[i]*100))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model (model, test_dataset):\n",
    "\t'''\n",
    "\tevaluate_model is used to plot some statistics about the performance on the test set\n",
    "\t:param model: model to consider\n",
    "\t'''\n",
    "\tlabels_d= ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "\n",
    "\t# get predictions\n",
    "\ty_score = model.predict(test_generator)\n",
    "\t# convert predictions to classes\n",
    "\ty_pred = np.argmax(y_score, axis=-1)\n",
    "\t# get true classes\n",
    "\ty_true = test_generator.classes\n",
    "\t# extract class labels\n",
    "\tclass_labels = list(test_generator.class_indices.keys())\n",
    "\t\n",
    "\tprint(\"Classification report: \")\n",
    "\tprint(metrics.classification_report(y_true, y_pred, target_names=class_labels,digits = 4))\n",
    "\t# create and show confusion matrix and roc\n",
    "\tmetrics.ConfusionMatrixDisplay.from_predictions(y_true, y_pred,display_labels=class_labels, xticks_rotation='vertical')\n",
    "\tplot_roc_curve(y_true, y_score, 4, class_labels)\n",
    " \n",
    "set_seed()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se il modello riesce ad apprendere correttamente, si dovrebbe osservare un andamento decrescente della loss e un andamento crescente dell'accuracy nel training set. Tuttavia, se la rete ha una capacità eccessiva rispetto al problema da risolvere, può incorrere in overfitting: in tal caso si ha un abbassamento della loss e un aumento dell'accuracy sul training set, ma un peggioramento delle performance sulla validation set (ovvero un aumento della validation loss e un abbassamento della validation accuracy)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CLAHE preprocessing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/content/drive/MyDrive/BrainTumorDataset/\"\n",
    "\n",
    "glioma_tumor_path = os.path.join(dataset_path, 'Preprocessed/Train/glioma_tumor/')\n",
    "meningioma_tumor_path = os.path.join(dataset_path, 'Preprocessed/Train/meningioma_tumor/')\n",
    "no_tumor_path = os.path.join(dataset_path, 'Preprocessed/Train/no_tumor/')\n",
    "pituitary_tumor_path = os.path.join(dataset_path, 'Preprocessed/Train/pituitary_tumor/')\n",
    "\n",
    "output_path = os.path.join(dataset_path, 'Preprocessed/CLAHE/')\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per applicare la trasformazione CLAHE a un'immagine\n",
    "def apply_clahe(image_path, output_path):\n",
    "    image = cv2.imread(image_path, 0)  # Carica l'immagine in scala di grigi\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))  # Crea l'oggetto CLAHE\n",
    "    clahe_image = clahe.apply(image)  # Applica la trasformazione CLAHE all'immagine\n",
    "    cv2.imwrite(output_path, clahe_image)  # Salva l'immagine trasformata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elabora le immagini nella cartella glioma_tumor\n",
    "for entry in glioma_tumor_entries:\n",
    "    image_path = os.path.join(glioma_tumor_path, entry)\n",
    "    output_subfolder = os.path.join(output_path, 'Train/glioma_tumor/')\n",
    "    os.makedirs(output_subfolder, exist_ok=True)\n",
    "    output_image_path = os.path.join(output_subfolder, entry)\n",
    "    apply_clahe(image_path, output_image_path)\n",
    "\n",
    "# Elabora le immagini nella cartella meningioma_tumor\n",
    "for entry in meningioma_entries:\n",
    "    image_path = os.path.join(meningioma_tumor_path, entry)\n",
    "    output_subfolder = os.path.join(output_path, 'Train/meningioma_tumor/')\n",
    "    os.makedirs(output_subfolder, exist_ok=True)\n",
    "    output_image_path = os.path.join(output_subfolder, entry)\n",
    "    apply_clahe(image_path, output_image_path)\n",
    "\n",
    "# Elabora le immagini nella cartella no_tumor\n",
    "for entry in no_tumor_entries:\n",
    "    image_path = os.path.join(no_tumor_path, entry)\n",
    "    output_subfolder = os.path.join(output_path, 'Train/no_tumor/')\n",
    "    os.makedirs(output_subfolder, exist_ok=True)\n",
    "    output_image_path = os.path.join(output_subfolder, entry)\n",
    "    apply_clahe(image_path, output_image_path)\n",
    "\n",
    "# Elabora le immagini nella cartella pituitary_tumor\n",
    "for entry in pituitary_tumor_entries:\n",
    "    image_path = os.path.join(pituitary_tumor_path, entry)\n",
    "    output_subfolder = os.path.join(output_path, 'Train/pituitary_tumor/')\n",
    "    os.makedirs(output_subfolder, exist_ok=True)\n",
    "    output_image_path = os.path.join(output_subfolder, entry)\n",
    "    apply_clahe(image_path, output_image_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
