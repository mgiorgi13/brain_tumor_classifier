{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/content/drive/MyDrive/BrainTumorDataset\"\n",
    "\n",
    "def set_seed ():\n",
    "\t''' \n",
    "\tset_seed is used to obtain reproducible results using keras during the development phase\n",
    "\t'''\n",
    "\tseed = 10\n",
    "\t# The below is necessary for reproducible results of certain Python hash-based operations.\n",
    "\tos.environ[\"PYTHONHASHSEED\"]=\"0\"\n",
    "\t# The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "\tnp.random.seed(seed)\n",
    "\t# The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "\trn.seed(seed)\n",
    "\t# The below tf.random.set_seed will make x number generation in TensorFlow have a well-defined initial state.\n",
    "\ttf.random.set_seed(seed)          \n",
    "\n",
    "def dataset_load():\n",
    "    '''\n",
    "    load dataset from folder, shuffle it and categorize labels from 0 to 3 (4 classes)\n",
    "    '''\n",
    "    labels = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "    image_size = 250\n",
    "    X_dataset = []\n",
    "    y_dataset = []\n",
    "    for lb in labels:\n",
    "        folderPath = os.path.join('/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Unified', lb)\n",
    "        for j in tqdm(os.listdir(folderPath)):\n",
    "            img = cv2.imread(os.path.join(folderPath,j))\n",
    "            img = cv2.resize(img,(image_size, image_size))\n",
    "            X_dataset.append(img)\n",
    "            y_dataset.append(lb)\n",
    "\n",
    "    X_dataset = np.array(X_dataset)\n",
    "    y_dataset = np.array(y_dataset)\n",
    "\n",
    "    X_dataset, y_dataset = shuffle(X_dataset, y_dataset, random_state=42)\n",
    "\n",
    "    y_dataset_new = []\n",
    "    for i in y_dataset:\n",
    "       y_dataset_new.append(labels.index(i))\n",
    "    y_dataset = y_dataset_new\n",
    "    y_dataset = tf.keras.utils.to_categorical(y_dataset,4)\n",
    "\n",
    "    return X_dataset, y_dataset\n",
    "\n",
    "def show_training_and_validation_performance(history):\n",
    "\t'''\n",
    "\tshow_training_and_validation_performance is used to plot the performances during the training phase\n",
    "\t:param history: object in which are recorded all the events\n",
    "\t'''\n",
    "\tacc = history.history['accuracy']\n",
    "\tval_acc = history.history['val_accuracy']\n",
    "\tloss = history.history['loss']\n",
    "\tval_loss = history.history['val_loss']\n",
    "\n",
    "\tepochs = range(len(acc))\n",
    "\n",
    "\tplt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "\tplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "\tplt.title('Training and validation accuracy')\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.figure()\n",
    "\n",
    "\tplt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "\tplt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "\tplt.title('Training and validation loss')\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.show()\n",
    "\n",
    "def compile_model (model, optimizer='adam', learning_rate = 0.001):\n",
    "\t'''\n",
    "\tcompile_model is used to compile the current model\n",
    "\t:param model: model to compile\n",
    "\t:param optimizer: optimizer to be used\n",
    "\t:param learning_rate: learning rate parameter for the optimizer\n",
    "\t'''\n",
    "\tif optimizer == 'adam':\n",
    "\t\tmodel.compile(loss=\"binary_crossentropy\",\n",
    "\t\toptimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "\t\tmetrics=[\"accuracy\"])\n",
    "\telif optimizer == 'rmsprop':\n",
    "\t\tmodel.compile(loss=\"binary_crossentropy\",\n",
    "\t\t\t\t\toptimizer = optimizers.RMSprop(learning_rate=learning_rate),\n",
    "\t\t\t\t\tmetrics=['accuracy'])\n",
    "\tmodel.summary()\n",
    "\n",
    "def run_model (model, model_name, epochs = 20, patience=5, monitor='val_loss'):\n",
    "\t'''\n",
    "\trun_model is used to run the current mode\n",
    "\t:param model: model to run\n",
    "\t:param model_name: name given to save the model\n",
    "\t:param epochs: how many epochs to do\n",
    "\t:param patience: patience value for Early Stopping\n",
    "\t:param monitor: what to monitor for Early Stopping and Model Checkpoint\n",
    "\t'''\n",
    "\t# local save path for the models\n",
    "\tsave_path = dataset_path + '/' + model_name + '.h5'\n",
    "\tcallbacks_list = [\n",
    "\t\t\t\t\tkeras.callbacks.EarlyStopping(monitor=monitor, patience=patience),\n",
    "\t\t\t\t\tkeras.callbacks.ModelCheckpoint(\n",
    "\t\t\t\t\t\tfilepath = save_path,\n",
    "\t\t\t\t\t\tmonitor=monitor,\n",
    "\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\tsave_best_only=True)\n",
    "\t\t\t\t\t]\n",
    "\thistory = model.fit(train_dataset,\n",
    "\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\tvalidation_data=validation_dataset,\n",
    "\t\t\t\t\t\tcallbacks=callbacks_list)\n",
    "\t# save on Drive only the best model\n",
    "\tshutil.copy(save_path, dataset_path + '/' + model_name + '.h5')\n",
    "\tshow_training_and_validation_performance(history)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from itertools import cycle\n",
    "\n",
    "def plot_roc_curve(y_test, y_pred):\n",
    "\t'''\n",
    "\tplot_roc_curve is used to plot the ROC curve\n",
    "\t:param y_test: true labels\n",
    "\t:param y_pred: predicted labels\n",
    "\t'''\n",
    "\tlabels = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "\tfpr = dict()\n",
    "\ttpr = dict()\n",
    "\troc_auc = dict()\n",
    "\tfor i in range(4):\n",
    "\t\tfpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "\t\troc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "\n",
    "\tcolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green'])\n",
    "\tfor i, color in zip(range(4), colors):\n",
    "\t\tplt.plot(\n",
    "\t\t\tfpr[i],\n",
    "\t\t\ttpr[i],\n",
    "\t\t\tcolor=color,\n",
    "\t\t\tlw=2,\n",
    "\t\t\tlabel='ROC curve of class {0} (area = {1:0.2f})'.format(labels[i], roc_auc[i]),\n",
    "\t\t)\n",
    "\n",
    "\tplt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\tplt.xlim([0.0, 1.0])\n",
    "\tplt.ylim([0.0, 1.05])\n",
    "\tplt.xlabel('False Positive Rate')\n",
    "\tplt.ylabel('True Positive Rate')\n",
    "\tplt.title('Some extension of Receiver operating characteristic to multiclass')\n",
    "\tplt.legend(loc='lower right')\n",
    "\tplt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "\tlabels = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "\ty_pred = np.argmax(y_pred, axis=1)\n",
    "\ty_test = np.argmax(y_test, axis=1)\n",
    "\tcm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\tdisp = ConfusionMatrixDisplay(confusion_matrix=cm)#, display_labels=['0', '1'])\n",
    "\tdisp.plot()\n",
    "\tplt.show()\n",
    "\n",
    "def evaluate_model (model, test_dataset):\n",
    "\t'''\n",
    "\tevaluate_model is used to plot some statistics about the performance on the test set\n",
    "\t:param model: model to consider\n",
    "\t'''\n",
    "\ty_score = model.predict(test_dataset)\n",
    "\ty_pred = np.rint(y_score) # to have 0 or 1\n",
    "\ty_true = tf.concat([labels_batch for data_batch, labels_batch in test_dataset], axis = 0)\n",
    "\tprint(\"Classification report: \")\n",
    "\tprint(metrics.classification_report(y_true,y_pred,digits = 4))\n",
    "\tmetrics.ConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n",
    "\tplot_roc_curve(y_true,y_pred)\n",
    "\tconfusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
