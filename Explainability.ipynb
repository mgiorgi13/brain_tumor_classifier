{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential ,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Drive connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3920 images belonging to 4 classes.\n",
      "Found 1304 images belonging to 4 classes.\n",
      "Found 1304 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, roc_auc_score\n",
    "\n",
    "dataset_path = \"/content/drive/MyDrive/BrainTumorDataset\"\n",
    "\n",
    "# Percorso della cartella \"unified\" che contiene le sottocartelle delle classi\n",
    "base_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Unified\"\n",
    "\n",
    "# Definisci i percorsi per il set di test, di validazione e di addestramento\n",
    "test_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Test\"\n",
    "val_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Validation\"\n",
    "train_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Train\"\n",
    "\n",
    "def set_seed ():\n",
    "\t''' \n",
    "\tset_seed is used to obtain reproducible results using keras during the development phase\n",
    "\t'''\n",
    "\tseed = 10\n",
    "\t# The below is necessary for reproducible results of certain Python hash-based operations.\n",
    "\tos.environ[\"PYTHONHASHSEED\"]=\"0\"\n",
    "\t# The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "\tnp.random.seed(seed)\n",
    "\t# The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "\trn.seed(seed)\n",
    "\t# The below tf.random.set_seed will make x number generation in TensorFlow have a well-defined initial state.\n",
    "\ttf.random.set_seed(seed)     \n",
    "\n",
    "# Definisci le dimensioni delle immagini\n",
    "image_size = 250\n",
    "batch_size = 32\n",
    "\n",
    "# Crea un oggetto ImageDataGenerator per il preprocessing delle immagini\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Carica le immagini dal set di addestramento\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Carica le immagini dal set di test\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Carica le immagini dal set di validazione\n",
    "val_generator = data_generator.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "     \n",
    "\n",
    "def show_training_and_validation_performance(history):\n",
    "\t'''\n",
    "\tshow_training_and_validation_performance is used to plot the performances during the training phase\n",
    "\t:param history: object in which are recorded all the events\n",
    "\t'''\n",
    "\tacc = history.history['accuracy']\n",
    "\tval_acc = history.history['val_accuracy']\n",
    "\tloss = history.history['loss']\n",
    "\tval_loss = history.history['val_loss']\n",
    "\n",
    "\tepochs = range(len(acc))\n",
    "\n",
    "\tplt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "\tplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "\tplt.title('Training and validation accuracy')\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.figure()\n",
    "\n",
    "\tplt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "\tplt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "\tplt.title('Training and validation loss')\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.show()\n",
    "\n",
    "def compile_model (model, optimizer='adam', learning_rate = 0.001):\n",
    "\t'''\n",
    "\tcompile_model is used to compile the current model\n",
    "\t:param model: model to compile\n",
    "\t:param optimizer: optimizer to be used\n",
    "\t:param learning_rate: learning rate parameter for the optimizer\n",
    "\t'''\n",
    "\tif optimizer == 'adam':\n",
    "\t\tmodel.compile(loss=\"categorical_crossentropy\",\n",
    "\t\toptimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "\t\tmetrics=[\"accuracy\"])\n",
    "\telif optimizer == 'rmsprop':\n",
    "\t\tmodel.compile(loss=\"categorical_crossentropy\",\n",
    "\t\t\t\t\toptimizer = optimizers.RMSprop(learning_rate=learning_rate),\n",
    "\t\t\t\t\tmetrics=['accuracy'])\n",
    "\tmodel.summary()\n",
    "\n",
    "def run_model (model, model_name, epochs = 100, patience=5, monitor='val_loss'):\n",
    "\t'''\n",
    "\trun_model is used to run the current mode\n",
    "\t:param model: model to run\n",
    "\t:param model_name: name given to save the model\n",
    "\t:param epochs: how many epochs to do\n",
    "\t:param patience: patience value for Early Stopping\n",
    "\t:param monitor: what to monitor for Early Stopping and Model Checkpoint\n",
    "\t'''\n",
    "\t# local save path for the models\n",
    "\tsave_path = dataset_path + '/' + model_name + '.h5'\n",
    "\tcallbacks_list = [\n",
    "\t\t\t\t\tkeras.callbacks.EarlyStopping(monitor=monitor, patience=patience),\n",
    "\t\t\t\t\tkeras.callbacks.ModelCheckpoint(\n",
    "\t\t\t\t\t\tfilepath = save_path,\n",
    "\t\t\t\t\t\tmonitor=monitor,\n",
    "\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\tsave_best_only=True)\n",
    "\t\t\t\t\t]\n",
    "\thistory = model.fit(train_generator,\n",
    "\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\tvalidation_data=val_generator,\n",
    "\t\t\t\t\t\tcallbacks=callbacks_list)\n",
    "\t# save on Drive only the best model\n",
    "\tshow_training_and_validation_performance(history)\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred, n_classes, class_labels):\n",
    "\n",
    "    # Converti le etichette di classe in formato binario\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_binary = lb.fit_transform(y_true)\n",
    "\n",
    "    # Calcola i tassi di FPR e TPR per ogni classe\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = metrics.roc_curve(y_true_binary[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "    plt.figure()\n",
    "    colors = ['blue', 'red', 'green', 'orange']  # Colori per le diverse classi\n",
    "\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, label='ROC curve {0} ({1:0.2f}%)'.format(class_labels[i], roc_auc[i]*100))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model (model, test_dataset):\n",
    "\t'''\n",
    "\tevaluate_model is used to plot some statistics about the performance on the test set\n",
    "\t:param model: model to consider\n",
    "\t'''\n",
    "\tlabels_d= ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "\n",
    "\t# get predictions\n",
    "\ty_score = model.predict(test_generator)\n",
    "\t# convert predictions to classes\n",
    "\ty_pred = np.argmax(y_score, axis=-1)\n",
    "\t# get true classes\n",
    "\ty_true = test_generator.classes\n",
    "\t# extract class labels\n",
    "\tclass_labels = list(test_generator.class_indices.keys())\n",
    "\t\n",
    "\tprint(\"Classification report: \")\n",
    "\tprint(metrics.classification_report(y_true, y_pred, target_names=class_labels,digits = 4))\n",
    "\t# create and show confusion matrix and roc\n",
    "\tmetrics.ConfusionMatrixDisplay.from_predictions(y_true, y_pred,display_labels=class_labels, xticks_rotation='vertical')\n",
    "\tplot_roc_curve(y_true, y_score, 4, class_labels)\n",
    "\n",
    "def get_index_by_layer_name(model, layer_name):\n",
    "  '''\n",
    "  get_index_by_layer_name is used to retrieve the index of a specific layer\n",
    "  :param model: model to check\n",
    "  :param layer_name: name of the layer we want to get the index of\n",
    "  :return: the index of the layer named as defined in layer_name\n",
    "  '''\n",
    "  for index, layer in enumerate(model.layers):\n",
    "      if layer.name == layer_name:\n",
    "          return index \n",
    "\n",
    "def clear(model):\n",
    "\tdel model\n",
    "\tK.clear_session() \n",
    "\n",
    "set_seed ()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path)\n",
    "# get a random image from test set\n",
    "img_path = random.choice(test_generator.filepaths)\n",
    "# load the image\n",
    "sample_img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_tensor = image.img_to_array(sample_img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "# Its shape is (1, 224, 224, 1)\n",
    "print(img_tensor.shape)\n",
    "\n",
    "\n",
    "# display it\n",
    "\n",
    "plt.imshow(img_tensor[0].astype('uint8'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = []\n",
    "layer_names = []\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, (layers.Conv2D, layers.MaxPooling2D)):\n",
    "        print(layer.name)\n",
    "        layer_outputs.append(layer.output)\n",
    "        layer_names.append(layer.name)\n",
    "activation_model = keras.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "# This will return a list of N Numpy arrays:\n",
    "# one array per layer activation\n",
    "activations = activation_model.predict(img_tensor)\n",
    "print(len(activations))\n",
    "for out in activations:\n",
    "  print(out.shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
