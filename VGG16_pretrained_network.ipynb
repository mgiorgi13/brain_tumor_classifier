{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEOV_XuJ5YFW"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i3cajnYA5YFb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Sequential ,load_model\n",
        "from keras.layers import Dense, Dropout, Flatten\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIIhAB5I5YHa"
      },
      "source": [
        "## Google Drive connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfYIIO4K5YHb",
        "outputId": "dc2092f5-eb24-4ee3-b0bd-92fffc27e9bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JERD8JE5YHe"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33TGEcCA5YHe",
        "outputId": "be004730-397d-4a20-a14f-0a33ee576216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3920 images belonging to 4 classes.\n",
            "Found 1304 images belonging to 4 classes.\n",
            "Found 1304 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/BrainTumorDataset\"\n",
        "\n",
        "# Percorso della cartella \"unified\" che contiene le sottocartelle delle classi\n",
        "base_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Unified\"\n",
        "\n",
        "# Definisci i percorsi per il set di test, di validazione e di addestramento\n",
        "test_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Test\"\n",
        "val_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Validation\"\n",
        "train_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Train\"\n",
        "\n",
        "def set_seed ():\n",
        "\t''' \n",
        "\tset_seed is used to obtain reproducible results using keras during the development phase\n",
        "\t'''\n",
        "\tseed = 10\n",
        "\t# The below is necessary for reproducible results of certain Python hash-based operations.\n",
        "\tos.environ[\"PYTHONHASHSEED\"]=\"0\"\n",
        "\t# The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
        "\tnp.random.seed(seed)\n",
        "\t# The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
        "\trn.seed(seed)\n",
        "\t# The below tf.random.set_seed will make x number generation in TensorFlow have a well-defined initial state.\n",
        "\ttf.random.set_seed(seed)     \n",
        "\n",
        "# Definisci le dimensioni delle immagini\n",
        "image_size = 250\n",
        "batch_size = 32\n",
        "\n",
        "# Crea un oggetto ImageDataGenerator per il preprocessing delle immagini\n",
        "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Carica le immagini dal set di addestramento\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Carica le immagini dal set di test\n",
        "test_generator = data_generator.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Carica le immagini dal set di validazione\n",
        "val_generator = data_generator.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "     \n",
        "\n",
        "def show_training_and_validation_performance(history):\n",
        "\t'''\n",
        "\tshow_training_and_validation_performance is used to plot the performances during the training phase\n",
        "\t:param history: object in which are recorded all the events\n",
        "\t'''\n",
        "\tacc = history.history['accuracy']\n",
        "\tval_acc = history.history['val_accuracy']\n",
        "\tloss = history.history['loss']\n",
        "\tval_loss = history.history['val_loss']\n",
        "\n",
        "\tepochs = range(len(acc))\n",
        "\n",
        "\tplt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "\tplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "\tplt.title('Training and validation accuracy')\n",
        "\tplt.legend()\n",
        "\n",
        "\tplt.figure()\n",
        "\n",
        "\tplt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "\tplt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "\tplt.title('Training and validation loss')\n",
        "\tplt.legend()\n",
        "\n",
        "\tplt.show()\n",
        "\n",
        "def compile_model (model, optimizer='adam', learning_rate = 0.001):\n",
        "\t'''\n",
        "\tcompile_model is used to compile the current model\n",
        "\t:param model: model to compile\n",
        "\t:param optimizer: optimizer to be used\n",
        "\t:param learning_rate: learning rate parameter for the optimizer\n",
        "\t'''\n",
        "\tif optimizer == 'adam':\n",
        "\t\tmodel.compile(loss=\"categorical_crossentropy\",\n",
        "\t\toptimizer=optimizers.Adam(learning_rate=learning_rate),\n",
        "\t\tmetrics=[\"accuracy\"])\n",
        "\telif optimizer == 'rmsprop':\n",
        "\t\tmodel.compile(loss=\"categorical_crossentropy\",\n",
        "\t\t\t\t\toptimizer = optimizers.RMSprop(learning_rate=learning_rate),\n",
        "\t\t\t\t\tmetrics=['accuracy'])\n",
        "\tmodel.summary()\n",
        "\n",
        "def run_model (model, model_name, epochs = 100, patience=5, monitor='val_loss'):\n",
        "\t'''\n",
        "\trun_model is used to run the current mode\n",
        "\t:param model: model to run\n",
        "\t:param model_name: name given to save the model\n",
        "\t:param epochs: how many epochs to do\n",
        "\t:param patience: patience value for Early Stopping\n",
        "\t:param monitor: what to monitor for Early Stopping and Model Checkpoint\n",
        "\t'''\n",
        "\t# local save path for the models\n",
        "\tsave_path = dataset_path + '/' + model_name + '.h5'\n",
        "\tcallbacks_list = [\n",
        "\t\t\t\t\tkeras.callbacks.EarlyStopping(monitor=monitor, patience=patience),\n",
        "\t\t\t\t\tkeras.callbacks.ModelCheckpoint(\n",
        "\t\t\t\t\t\tfilepath = save_path,\n",
        "\t\t\t\t\t\tmonitor=monitor,\n",
        "\t\t\t\t\t\tverbose=1,\n",
        "\t\t\t\t\t\tsave_best_only=True)\n",
        "\t\t\t\t\t]\n",
        "\thistory = model.fit(train_generator,\n",
        "\t\t\t\t\t\tepochs=epochs,\n",
        "\t\t\t\t\t\tvalidation_data=val_generator,\n",
        "\t\t\t\t\t\tcallbacks=callbacks_list)\n",
        "\t# save on Drive only the best model\n",
        "\tshow_training_and_validation_performance(history)\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from itertools import cycle\n",
        "\n",
        "def plot_roc_curve(y_test, y_pred):\n",
        "\t'''\n",
        "\tplot_roc_curve is used to plot the ROC curve\n",
        "\t:param y_test: true labels\n",
        "\t:param y_pred: predicted labels\n",
        "\t'''\n",
        "\tlabels = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
        "\tfpr = dict()\n",
        "\ttpr = dict()\n",
        "\troc_auc = dict()\n",
        "\tfor i in range(4):\n",
        "\t\tfpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
        "\t\troc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "\n",
        "\tcolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green'])\n",
        "\tfor i, color in zip(range(4), colors):\n",
        "\t\tplt.plot(\n",
        "\t\t\tfpr[i],\n",
        "\t\t\ttpr[i],\n",
        "\t\t\tcolor=color,\n",
        "\t\t\tlw=2,\n",
        "\t\t\tlabel='ROC curve of class {0} (area = {1:0.2f})'.format(labels[i], roc_auc[i]),\n",
        "\t\t)\n",
        "\n",
        "\tplt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "\tplt.xlim([0.0, 1.0])\n",
        "\tplt.ylim([0.0, 1.05])\n",
        "\tplt.xlabel('False Positive Rate')\n",
        "\tplt.ylabel('True Positive Rate')\n",
        "\tplt.title('Some extension of Receiver operating characteristic to multiclass')\n",
        "\tplt.legend(loc='lower right')\n",
        "\tplt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def evaluate_model (model, test_dataset):\n",
        "\t'''\n",
        "\tevaluate_model is used to plot some statistics about the performance on the test set\n",
        "\t:param model: model to consider\n",
        "\t'''\n",
        "\tlabels_d= ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
        "\ty_score = model.predict(test_dataset)\n",
        "\ty_pred = np.rint(y_score) # to have 0 or 1\n",
        "\ty_true = tf.concat([labels_batch for data_batch, labels_batch in test_dataset], axis = 0)\n",
        "\tprint(\"Classification report: \")\n",
        "\tprint(metrics.classification_report(y_true,y_pred,digits = 4))\n",
        "\tmetrics.ConfusionMatrixDisplay.from_predictions(y_true, y_pred,labels=labels_d)\n",
        "\tplot_roc_curve(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZGNlxO15YHh"
      },
      "source": [
        "## Load VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "9de8ei-T5YHh",
        "outputId": "08463e8d-5a77-4d44-d351-e13d6c566ca4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-bb7f1af3d8d5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Valuta il modello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-e4f38bd4a23d>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_dataset)\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0mtensor_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to have 0 or 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'extend' is not defined"
          ]
        }
      ],
      "source": [
        "model = load_model(dataset_path + \"/VGG16.h5\")\n",
        "\n",
        "# Carica il modello VGG16 pre-addestrato, senza l'ultimo strato fully connected\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "# Aggiungi un nuovo strato fully connected all'ultimo layer di VGG16\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4, activation='softmax')) #4 classi di output\n",
        "\n",
        "# Congela i pesi del modello base, così da mantenere l'informazione appresa\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compila il modello\n",
        "compile_model(model)\n",
        "\n",
        "# Addestra il modello\n",
        "run_model(model,\"VGG16\")\n",
        "# Valuta il modello\n",
        "evaluate_model(model,test_generator)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}