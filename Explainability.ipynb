{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I_0LL7lzyz5X"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VTWnILPJyz5Z"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-23 19:48:17.182973: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "#!pip3 install tensorflow keras matplotlib scikit-learn\n",
        "# !pip3 install pydot\n",
        "# !pip3 install graphviz\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.cm as cm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import VGG16 , ResNet50, InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Sequential ,load_model\n",
        "from keras.layers import Dense, Dropout, Flatten\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "u6idz1ujyz5e"
      },
      "source": [
        "## Google Drive connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEHCTLMhyz5f",
        "outputId": "5af720ba-7e46-4579-ff7f-073ee7f7a0c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rvx07Z2pyz5h"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WAiJHt6yz5h",
        "outputId": "f5916118-9f8e-438c-cc4c-e9c3fb1007d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4488 images belonging to 4 classes.\n",
            "Found 646 images belonging to 4 classes.\n",
            "Found 646 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, roc_auc_score\n",
        "\n",
        "# su colab\n",
        "dataset_path = \"/content/drive/MyDrive/BrainTumorDataset\"\n",
        "\n",
        "# Percorso della cartella \"unified\" che contiene le sottocartelle delle classi\n",
        "base_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Unified\"\n",
        "\n",
        "# Definisci i percorsi per il set di test, di validazione e di addestramento\n",
        "test_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Test\"\n",
        "val_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Validation\"\n",
        "train_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Train\"\n",
        "\n",
        "# # per locale\n",
        "# dataset_path = \"BrainTumorDataset\"\n",
        "\n",
        "# # Percorso della cartella \"unified\" che contiene le sottocartelle delle classi\n",
        "# base_path = \"BrainTumorDataset/Preprocessed/Unified\"\n",
        "\n",
        "# # Definisci i percorsi per il set di test, di validazione e di addestramento\n",
        "# test_path = \"BrainTumorDataset/Preprocessed/Test\"\n",
        "# val_path = \"BrainTumorDataset/Preprocessed/Validation\"\n",
        "# train_path = \"BrainTumorDataset/Preprocessed/Train\"\n",
        "\n",
        "models_path = \"/content/drive/MyDrive/BrainTumorDataset/Models\"\n",
        "cnn_results_path = os.path.join(models_path, 'CNN')\n",
        "vgg16_results_path = os.path.join(models_path, 'VGG16')\n",
        "resnet50_results_path = os.path.join(models_path, 'ResNet50')\n",
        "inceptionv3_results_path = os.path.join(models_path, 'InceptionV3')\n",
        "\n",
        "#dict of labels\n",
        "labels_dict= {0:'glioma_tumor', 1:'meningioma_tumor', 2:'no_tumor', 3:'pituitary_tumor'}\n",
        "\n",
        "def set_seed ():\n",
        "\t''' \n",
        "\tset_seed is used to obtain reproducible results using keras during the development phase\n",
        "\t'''\n",
        "\tseed = 10\n",
        "\t# The below is necessary for reproducible results of certain Python hash-based operations.\n",
        "\tos.environ[\"PYTHONHASHSEED\"]=\"0\"\n",
        "\t# The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
        "\tnp.random.seed(seed)\n",
        "\t# The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
        "\trn.seed(seed)\n",
        "\t# The below tf.random.set_seed will make x number generation in TensorFlow have a well-defined initial state.\n",
        "\ttf.random.set_seed(seed)     \n",
        "\n",
        "# Definisci le dimensioni delle immagini\n",
        "image_size = 250\n",
        "batch_size = 32\n",
        "images_per_row = 16\n",
        "\n",
        "# Crea un oggetto ImageDataGenerator per il preprocessing delle immagini\n",
        "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Carica le immagini dal set di addestramento\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Carica le immagini dal set di test\n",
        "test_generator = data_generator.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Carica le immagini dal set di validazione\n",
        "val_generator = data_generator.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "     \n",
        "\n",
        "def show_training_and_validation_performance(history,path):\n",
        "\t'''\n",
        "\tshow_training_and_validation_performance is used to plot the performances during the training phase\n",
        "\t:param history: object in which are recorded all the events\n",
        "\t'''\n",
        "\tacc = history.history['accuracy']\n",
        "\tval_acc = history.history['val_accuracy']\n",
        "\tloss = history.history['loss']\n",
        "\tval_loss = history.history['val_loss']\n",
        "\n",
        "\tepochs = range(len(acc))\n",
        "\n",
        "\tplt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "\tplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "\tplt.title('Training and validation accuracy')\n",
        "\tplt.legend()\n",
        "\n",
        "\tplt.figure()\n",
        "\n",
        "\tplt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "\tplt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "\tplt.title('Training and validation loss')\n",
        "\tplt.legend()\n",
        "\n",
        "\tplt.savefig(path)\n",
        "\n",
        "\tplt.show()\n",
        "\n",
        "def compile_model (model, optimizer='adam', learning_rate = 0.001):\n",
        "\t'''\n",
        "\tcompile_model is used to compile the current model\n",
        "\t:param model: model to compile\n",
        "\t:param optimizer: optimizer to be used\n",
        "\t:param learning_rate: learning rate parameter for the optimizer\n",
        "\t'''\n",
        "\tif optimizer == 'adam':\n",
        "\t\tmodel.compile(loss=\"categorical_crossentropy\",\n",
        "\t\toptimizer=optimizers.Adam(learning_rate=learning_rate),\n",
        "\t\tmetrics=[\"accuracy\"])\n",
        "\telif optimizer == 'rmsprop':\n",
        "\t\tmodel.compile(loss=\"categorical_crossentropy\",\n",
        "\t\t\t\t\toptimizer = optimizers.RMSprop(learning_rate=learning_rate),\n",
        "\t\t\t\t\tmetrics=['accuracy'])\n",
        "\tmodel.summary()\n",
        "\n",
        "def run_model (model, type, model_name, epochs = 100, patience=5, monitor='val_loss'):\n",
        "\t'''\n",
        "\trun_model is used to run the current mode\n",
        "\t:param model: model to run\n",
        "\t:param model_name: name given to save the model\n",
        "\t:param type: type of model, CNN, VGG16, ResNet50, InceptionV3\n",
        "\t:param epochs: how many epochs to do\n",
        "\t:param patience: patience value for Early Stopping\n",
        "\t:param monitor: what to monitor for Early Stopping and Model Checkpoint\n",
        "\t'''\n",
        "\t# local save path for the models\n",
        "\tsave_path = os.path.join(models_path, type + '/' + model_name + '.h5') \n",
        "\tcallbacks_list = [\n",
        "\t\t\t\t\tkeras.callbacks.EarlyStopping(monitor=monitor, patience=patience),\n",
        "\t\t\t\t\tkeras.callbacks.ModelCheckpoint(\n",
        "\t\t\t\t\t\tfilepath = save_path,\n",
        "\t\t\t\t\t\tmonitor=monitor,\n",
        "\t\t\t\t\t\tverbose=1,\n",
        "\t\t\t\t\t\tsave_best_only=True)\n",
        "\t\t\t\t\t]\n",
        "\thistory = model.fit(train_generator,\n",
        "\t\t\t\t\t\tepochs=epochs,\n",
        "\t\t\t\t\t\tvalidation_data=val_generator,\n",
        "\t\t\t\t\t\tcallbacks=callbacks_list)\n",
        "\t# save on Drive only the best model\n",
        "\tshow_training_and_validation_performance(history,os.path.join(models_path, type + '/' + model_name + '_validation.png'))\n",
        "\n",
        "def plot_roc_curve(y_true, y_pred, n_classes, class_labels, model_name, type):\n",
        "\n",
        "    # Converti le etichette di classe in formato binario\n",
        "    lb = LabelBinarizer()\n",
        "    y_true_binary = lb.fit_transform(y_true)\n",
        "\n",
        "    # Calcola i tassi di FPR e TPR per ogni classe\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = metrics.roc_curve(y_true_binary[:, i], y_pred[:, i])\n",
        "        roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
        "\n",
        "    plt.figure()\n",
        "    colors = ['blue', 'red', 'green', 'orange']  # Colori per le diverse classi\n",
        "\n",
        "    for i, color in zip(range(n_classes), colors):\n",
        "        plt.plot(fpr[i], tpr[i], color=color, label='ROC curve {0} ({1:0.2f}%)'.format(class_labels[i], roc_auc[i]*100))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.0])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(os.path.join(models_path, type + '/' + model_name + '_ROC.png'))\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model (model, test_generator, model_name, type):\n",
        "\t'''\n",
        "\tevaluate_model is used to plot some statistics about the performance on the test set\n",
        "\t:param model: model to consider\n",
        "\t'''\n",
        "\tlabels_d= ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
        "\n",
        "\t# get predictions\n",
        "\ty_score = model.predict(test_generator)\n",
        "\t# convert predictions to classes\n",
        "\ty_pred = np.argmax(y_score, axis=-1)\n",
        "\t# get true classes\n",
        "\ty_true = test_generator.classes\n",
        "\t# extract class labels\n",
        "\tclass_labels = list(test_generator.class_indices.keys())\n",
        "\t\n",
        "\tprint(\"Classification report: \")\n",
        "\t# create and show classification report\n",
        "\tprint(metrics.classification_report(y_true, y_pred, target_names=class_labels,digits = 4))\n",
        "\t# save classification report\n",
        "\twith open(os.path.join(models_path, type + '/' + model_name + '_classification_report.txt'), 'w') as f:\n",
        "\t\tf.write(metrics.classification_report(y_true, y_pred, target_names=class_labels,digits = 4))\n",
        "\n",
        "\t# create and show confusion matrix\t\n",
        "\tcm = confusion_matrix(y_true, y_pred)\t\n",
        "\tdisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "\tdisp.plot(xticks_rotation=45)\n",
        "\t\n",
        "\t# save confusion matrix\n",
        "\tplt.savefig(os.path.join(models_path, type, model_name + '_confusion_matrix.png'), bbox_inches='tight', pad_inches=0.1)\n",
        "\tplt.show()\n",
        "\n",
        "\tplot_roc_curve(y_true, y_score, 4, class_labels, model_name, type)\n",
        "\n",
        "def get_conv_pool_layers(model, img_path, target_size=(224, 224)):\n",
        "\timg_array = get_img(img_path, target_size=target_size)\n",
        "\t#get all conv and pooling layers\n",
        "\tlayer_outputs = []\n",
        "\tlayer_names = []\n",
        "\tfor layer in model.layers:\n",
        "\t\tif isinstance(layer, (layers.Conv2D, layers.MaxPooling2D)):\n",
        "\t\t\tlayer_outputs.append(layer.output)\n",
        "\t\t\tlayer_names.append(layer.name)\n",
        "\tactivation_model = keras.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "\t# This will return a list of N Numpy arrays:\n",
        "\t# one array per layer activation\n",
        "\tactivations = activation_model.predict(img_array)\n",
        "\treturn layer_names, activations\n",
        "\n",
        "def display_feature_map(layer_names, activations, layer_to_show = None, layer_to_skip = 0):\n",
        "\n",
        "\t#skip layers not required\n",
        "\tlayer_names = layer_names[layer_to_skip:]\n",
        "\tactivations = activations[layer_to_skip:]\n",
        "\n",
        "\tlayer_counter = layer_to_show\n",
        "\t# Now let's display our feature maps\n",
        "\tfor layer_name, layer_activation in zip(layer_names, activations):\n",
        "\t\t\t\n",
        "\t\tif layer_to_show != None:\n",
        "\t\t\tif layer_counter <= 0:\n",
        "\t\t\t\tbreak\n",
        "\t\t\tlayer_counter -= 1\n",
        "\t\t\n",
        "\t\t# This is the number of features in the feature map\n",
        "\t\tn_features = layer_activation.shape[-1]\n",
        "\n",
        "\t\t# The feature map has shape (1, size, size, n_features)\n",
        "\t\tsize = layer_activation.shape[1]\n",
        "\n",
        "\t\t# We will tile the activation channels in this matrix\n",
        "\t\tn_cols = n_features // images_per_row\n",
        "\t\tdisplay_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "\t\t# We'll tile each filter into this big horizontal grid\n",
        "\t\tfor col in range(n_cols):\n",
        "\t\t\t\tfor row in range(images_per_row):\n",
        "\t\t\t\t\t\tchannel_image = layer_activation[0,:, :, col * images_per_row + row]\n",
        "\t\t\t\t\t\t# Post-process the feature to make it visually palatable\n",
        "\t\t\t\t\t\tchannel_image -= channel_image.mean()\n",
        "\t\t\t\t\t\tchannel_image /= channel_image.std()\n",
        "\t\t\t\t\t\tchannel_image *= 64\n",
        "\t\t\t\t\t\tchannel_image += 128\n",
        "\t\t\t\t\t\tchannel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "\t\t\t\t\t\tdisplay_grid[col * size : (col + 1) * size, row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "\t\t# Display the grid\n",
        "\t\tscale = 1. / size\n",
        "\t\tplt.figure(figsize=(scale * display_grid.shape[1],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tscale * display_grid.shape[0]))\n",
        "\t\tplt.title(layer_name)\n",
        "\t\tplt.grid(False)\n",
        "\t\tplt.imshow(display_grid, aspect='auto', cmap='gray')\n",
        "\t\t\t\n",
        "\tplt.show()\n",
        "\n",
        "def head(layer_names, activations, number = 5):\n",
        "\tprint(\"---------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "\tdisplay_feature_map(layer_names, activations, number,0)\n",
        "\tprint(\"---------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "def tail(layer_names, activations, number = 5):\n",
        "\tprint(\"---------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "\tskip = len(layer_names) - number\n",
        "\tdisplay_feature_map(layer_names, activations, number,skip)\n",
        "\tprint(\"---------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "def get_img(img_path, target_size=(224,224)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    array = image.img_to_array(img)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "def get_img_for_pred(img_path, target_size=(224,224)):\n",
        "\timg = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "\timg_tensor = tf.keras.preprocessing.image.img_to_array(img)  # (height, width, channels)\n",
        "\timg_tensor = np.expand_dims(img_tensor, axis=0) \n",
        "\timg_tensor /= 255.\n",
        "\treturn img_tensor\n",
        "\n",
        "def decode_predictions(pred):\n",
        "\tclass_indices = np.argsort(pred)[0, ::-1][:4]  # Ottieni gli indici delle probabilità ordinate in modo decrescente per le prime 4 classi\n",
        "\tclass_probabilities = pred[0, class_indices]  # Probabilità corrispondenti alle classi selezionate\n",
        "\tclass_labels = [labels_dict[i] for i in class_indices]  # Etichette corrispondenti alle classi selezionate\n",
        "\n",
        "\tfor label, probability in zip(class_labels, class_probabilities):\n",
        "\t\tprint(f\"{label}: {probability*100:.2f}%\")\n",
        "\n",
        "def get_last_conv_layer(model):\n",
        "\tclass_layer_names = []\n",
        "\tlast_conv_layer = None\n",
        "\tfor layer in model.layers[::-1]:\n",
        "\t\tif isinstance(layer, keras.layers.Conv2D):\n",
        "\t\t\tlast_conv_layer = layer\n",
        "\t\t\tbreak\n",
        "\t\telse:\n",
        "\t\t\tclass_layer_names.append(layer.name)\n",
        "\tclass_layer_names = class_layer_names[::-1]\n",
        "\tif last_conv_layer is None:\n",
        "\t\t# if no conv layer is found then the model is not a CNN from scratch\n",
        "\t\t# so remove from list the functional layer (which is the pretrained model)\n",
        "\t\tclass_layer_names.pop(0)\n",
        "\treturn last_conv_layer, class_layer_names\n",
        "\n",
        "def GradCAM_process(model, img_path, target_size=(224,224), type='CNN'):\n",
        "\t# import image and make prediction on the given model\n",
        "\timg_tensor = get_img_for_pred(img_path, target_size=target_size)\n",
        "\tpreds = model.predict(img_tensor)\n",
        "\tdecode_predictions(preds)\n",
        "\n",
        "\t#get last conv layer and list of dense part of the loaded model\n",
        "\tlast_conv_layer, classifier_layer_names = get_last_conv_layer(model)\n",
        "\t#get last conv layer and list of dense part of the pretrained model\n",
        "\tconv_layer_names = []\n",
        "\tif(type == \"VGG16\"):\n",
        "\t\tconv_base = model.get_layer('vgg16')\n",
        "\t\tlast_conv, conv_layer_names = get_last_conv_layer(conv_base)\n",
        "\telif(type == \"ResNet50\"):\n",
        "\t\tconv_base = model.get_layer('resnet50')\n",
        "\t\tlast_conv = conv_base.get_layer('conv5_block3_out')\n",
        "\telif(type == \"InceptionV3\"):\n",
        "\t\tconv_base = model.get_layer('inception_v3')\n",
        "\t\tlast_conv = conv_base.get_layer('mixed10')\n",
        "\telse:\n",
        "\t\tconv_base = model\n",
        "\t\tlast_conv = last_conv_layer\n",
        "\t\t\n",
        "\t#create a model that map input to the last conv layer\n",
        "\tlast_conv_layer_model = keras.Model(conv_base.inputs, last_conv.output)\n",
        "\tclassifier_input = keras.Input(shape=last_conv.output.shape[1:])\n",
        "\n",
        "\t#create a classifier model that map the output of the last conv layer to the output of the loaded model\t\n",
        "\tx = classifier_input\n",
        "\tif(type != \"CNN\"):\n",
        "\t\t# add the remaing part of the pretrained model\n",
        "\t\tfor layer_name in conv_layer_names:\n",
        "\t\t\tx = conv_base.get_layer(layer_name)(x)\n",
        "\t#add the dense part of the loaded model\n",
        "\tfor layer_name in classifier_layer_names:\n",
        "\t\tx = model.get_layer(layer_name)(x)\n",
        "\tclassifier_model = keras.Model(classifier_input, x)\n",
        "\t\n",
        "\treturn img_tensor, last_conv_layer_model, classifier_model\n",
        "\n",
        "def create_heatmap(img_tensor,last_conv_layer_model,classifier_model):\n",
        "\t#compute gradient for input image respect to the activations of the last convolution layer\n",
        "\twith tf.GradientTape() as tape:\n",
        "\t\tlast_conv_layer_output = last_conv_layer_model(img_tensor) # output feature maps of the last conv layer.\n",
        "\t\ttape.watch(last_conv_layer_output)\n",
        "\t\tpreds = classifier_model(last_conv_layer_output)\n",
        "\t\ttop_pred_index = tf.argmax(preds[0])  # meningioma_tumor prediction index\n",
        "\t\ttop_class_channel = preds[:, top_pred_index] # meningioma_tumor prediction value\n",
        "\t#Gradient of the meningioma_tumor class with related to the output feature maps of last conv layer\n",
        "\tgrads = tape.gradient(top_class_channel, last_conv_layer_output) \n",
        "\t#Apply pooling and importance weighting to the gradient tensor to obtain heatmap of class activation\n",
        "\tpooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)).numpy() # evaluate the mean over the gradient tensor, for each channel separately\n",
        "\t\n",
        "\tweighted_last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "\tfor i in range(pooled_grads.shape[-1]):\n",
        "\t\tweighted_last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "\theatmap = np.mean(weighted_last_conv_layer_output, axis=-1)\n",
        "\theatmap = np.maximum(heatmap, 0)\n",
        "\theatmap /= np.max(heatmap)\n",
        "\n",
        "\treturn heatmap\n",
        "\n",
        "def superimposed_img(img_path, heatmaps, save_path):\n",
        "\tmodels = ['CNN', 'VGG16', 'ResNet50', 'InceptionV3']\n",
        "\timg = keras.utils.load_img(img_path)\n",
        "\timg = keras.utils.img_to_array(img)\n",
        "\n",
        "\tfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\tfig.suptitle('Superimposed Images', fontsize=16)\n",
        "\n",
        "\tfor i, ax in enumerate(axes.flat):\n",
        "\t\theatmap = heatmaps[i]\n",
        "\t\theatmap = np.uint8(255 * heatmap)\n",
        "\t\tjet = mpl.colormaps.get_cmap(\"jet\")\n",
        "\t\tjet_colors = jet(np.arange(256))[:, :3]\n",
        "\t\tjet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "\t\tjet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
        "\t\tjet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "\t\tjet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
        "\n",
        "\t\tsuperimposed_img = jet_heatmap * 0.8 + img\n",
        "\t\tsuperimposed_img = keras.utils.array_to_img(superimposed_img)\n",
        "\n",
        "\t\tax.imshow(superimposed_img)\n",
        "\t\tax.set_title(models[i])\n",
        "\t\tax.axis('off')\n",
        "\n",
        "\tplt.tight_layout()\n",
        "\tplt.savefig(save_path)\n",
        "\tplt.show()\n",
        "\n",
        "def plot_heatmaps(heatmaps):\n",
        "    models = ['CNN', 'VGG16', 'ResNet50', 'InceptionV3']\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "    fig.suptitle('Models Heatmap', fontsize=16)\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(heatmaps[i])\n",
        "        ax.set_title(models[i])\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def clear(model):\n",
        "\tdel model\n",
        "\tK.clear_session() \n",
        "\n",
        "set_seed ()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "scratch_path = os.path.join(dataset_path,\"Models/cnn_from_scratch_exp8/cnn_from_scratch_exp8.h5\")\n",
        "VGG16_path = os.path.join(dataset_path,\"Models/cnn_from_scratch_exp8/VGG16_250.h5\")\n",
        "ResNet50_path = os.path.join(dataset_path,\"Models/cnn_from_scratch_exp8/ResNet-50_256.h5\")\n",
        "InceptionV3_path = os.path.join(dataset_path,\"Models/cnn_from_scratch_exp8/InceptionV3_128_128_fine_tuning.h5\")\n",
        "\n",
        "scratch_model = load_model(scratch_path)\n",
        "VGG16_model = load_model(VGG16_path)\n",
        "ResNet50_model = load_model(ResNet50_path)\n",
        "InceptionV3_model = load_model(InceptionV3_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualize Conv and Pooling activation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "c5lEVfxiFnbU"
      },
      "source": [
        "## Meningioma Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get a random image from test set\n",
        "img_path = os.path.join(test_path,\"meningioma_tumor/meningioma_tumor_307.jpg\")\n",
        "# load the image\n",
        "img_array = get_img(img_path, target_size=(image_size, image_size))\n",
        "# display it\n",
        "plt.imshow(img_array[0].astype('uint8'))\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CNN from Scratch Vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = scratch_model\n",
        "\n",
        "layer_names, activations = get_conv_pool_layers(model, img_path, target_size=(image_size, image_size))\n",
        "\n",
        "# print layer and shape \n",
        "count = 1\n",
        "for layer_name, activation in zip(layer_names, activations):\n",
        "    print(str(count), \" : \", layer_name, activation.shape)\n",
        "    count += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display_feature_map(layer_names, activations,)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VGG16 Vision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = VGG16_model.get_layer('vgg16')\n",
        "\n",
        "layer_names, activations = get_conv_pool_layers(model, img_path, target_size=(224, 224))\n",
        "\n",
        "# print layer and shape \n",
        "count = 1\n",
        "for layer_name, activation in zip(layer_names, activations):\n",
        "    print(str(count), \" : \", layer_name, activation.shape)\n",
        "    count += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "head(layer_names, activations,1)\n",
        "tail(layer_names, activations,1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ResNet50 Vision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ResNet50_model.get_layer('resnet50')\n",
        "layer_names, activations = get_conv_pool_layers(model, img_path, target_size=(224, 224))\n",
        "\n",
        "# print layer and shape \n",
        "count = 1\n",
        "for layer_name, activation in zip(layer_names, activations):\n",
        "    print(str(count), \" : \", layer_name, activation.shape)\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "head(layer_names, activations,1)\n",
        "tail(layer_names, activations,1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## InceptionV3 Vision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = InceptionV3_model.get_layer('inception_v3')\n",
        "\n",
        "layer_names, activations = get_conv_pool_layers(model, img_path, target_size=(224, 224))\n",
        "\n",
        "# print layer and shape \n",
        "count = 1\n",
        "for layer_name, activation in zip(layer_names, activations):\n",
        "    print(str(count), \" : \", layer_name, activation.shape)\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "head(layer_names, activations,1)\n",
        "tail(layer_names, activations,1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Glioma Heatmap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get a random image from test set\n",
        "img_path = os.path.join(test_path,\"glioma_tumor/glioma_tumor_1.jpg\")\n",
        "# load the image\n",
        "img_array = get_img(img_path, target_size=(image_size, image_size))\n",
        "# display it\n",
        "plt.imshow(img_array[0].astype('uint8'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Scratch model\")\n",
        "img_tensor_scratch, last_conv_model_scratch, classifier_model_scratch = GradCAM_process(scratch_model,img_path,(image_size,image_size))\n",
        "print(\"\\nVGG16 model\")\n",
        "img_tensor_VGG16, last_conv_model_VGG16, classifier_model_VGG16 = GradCAM_process(VGG16_model,img_path,(224,224),'VGG16')\n",
        "print(\"\\nResNet50 model\")\n",
        "img_tensor_ResNet50, last_conv_model_ResNet50, classifier_model_ResNet50 = GradCAM_process(ResNet50_model,img_path,(224,224),'ResNet50')\n",
        "print(\"\\nInceptionV3 model\")\n",
        "img_tensor_InceptionV3, last_conv_model_InceptionV3, classifier_model_InceptionV3 = GradCAM_process(InceptionV3_model,img_path,(224,224),'InceptionV3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "heatmap_scratch = create_heatmap(img_tensor_scratch, last_conv_model_scratch, classifier_model_scratch)\n",
        "heatmap_VGG16 = create_heatmap(img_tensor_VGG16, last_conv_model_VGG16, classifier_model_VGG16)\n",
        "heatmap_ResNet50 = create_heatmap(img_tensor_ResNet50, last_conv_model_ResNet50, classifier_model_ResNet50)\n",
        "heatmap_InceptionV3 = create_heatmap(img_tensor_InceptionV3, last_conv_model_InceptionV3, classifier_model_InceptionV3)\n",
        "plot_heatmaps([heatmap_scratch,heatmap_VGG16,heatmap_ResNet50,heatmap_InceptionV3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_path = os.path.join(dataset_path,\"Models/cnn_from_scratch_exp8/heatmap_notumor.jpg\")\n",
        "superimposed_img(img_path,[heatmap_scratch,heatmap_VGG16,heatmap_ResNet50,heatmap_InceptionV3],save_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# No Tumor Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kL4qb8bOFrgs",
        "outputId": "02bea4c0-2710-415a-d786-ac957468710a"
      },
      "outputs": [],
      "source": [
        "# get a random image from test set\n",
        "img_path = os.path.join(test_path,\"no_tumor/no_tumor_4.jpg\")\n",
        "# load the image\n",
        "img_array = get_img(img_path, target_size=(image_size, image_size))\n",
        "\n",
        "# display it\n",
        "plt.imshow(img_array[0].astype('uint8'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "p1e0Qvik-YEs",
        "outputId": "d2be60b6-6981-4a11-8096-4187fd33b82d"
      },
      "outputs": [],
      "source": [
        "print(\"Scratch model\")\n",
        "img_tensor_scratch, last_conv_model_scratch, classifier_model_scratch = GradCAM_process(scratch_model,img_path,(image_size,image_size))\n",
        "print(\"\\nVGG16 model\")\n",
        "img_tensor_VGG16, last_conv_model_VGG16, classifier_model_VGG16 = GradCAM_process(VGG16_model,img_path,(224,224),'VGG16')\n",
        "print(\"\\nResNet50 model\")\n",
        "img_tensor_ResNet50, last_conv_model_ResNet50, classifier_model_ResNet50 = GradCAM_process(ResNet50_model,img_path,(224,224),'ResNet50')\n",
        "print(\"\\nInceptionV3 model\")\n",
        "img_tensor_InceptionV3, last_conv_model_InceptionV3, classifier_model_InceptionV3 = GradCAM_process(InceptionV3_model,img_path,(224,224),'InceptionV3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "heatmap_scratch = create_heatmap(img_tensor_scratch, last_conv_model_scratch, classifier_model_scratch)\n",
        "heatmap_VGG16 = create_heatmap(img_tensor_VGG16, last_conv_model_VGG16, classifier_model_VGG16)\n",
        "heatmap_ResNet50 = create_heatmap(img_tensor_ResNet50, last_conv_model_ResNet50, classifier_model_ResNet50)\n",
        "heatmap_InceptionV3 = create_heatmap(img_tensor_InceptionV3, last_conv_model_InceptionV3, classifier_model_InceptionV3)\n",
        "plot_heatmaps([heatmap_scratch,heatmap_VGG16,heatmap_ResNet50,heatmap_InceptionV3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_path = os.path.join(dataset_path,\"Models/cnn_from_scratch_exp8/heatmap_notumor.jpg\")\n",
        "superimposed_img(img_path,[heatmap_scratch,heatmap_VGG16,heatmap_ResNet50,heatmap_InceptionV3],save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
