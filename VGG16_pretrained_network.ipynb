{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Google Drive connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/content/drive/MyDrive/BrainTumorDataset\"\n",
    "\n",
    "# Percorso della cartella \"unified\" che contiene le sottocartelle delle classi\n",
    "base_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Unified\"\n",
    "\n",
    "# Definisci i percorsi per il set di test, di validazione e di addestramento\n",
    "test_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Test\"\n",
    "val_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Validation\"\n",
    "train_path = \"/content/drive/MyDrive/BrainTumorDataset/Preprocessed/Train\"\n",
    "\n",
    "def set_seed ():\n",
    "\t''' \n",
    "\tset_seed is used to obtain reproducible results using keras during the development phase\n",
    "\t'''\n",
    "\tseed = 10\n",
    "\t# The below is necessary for reproducible results of certain Python hash-based operations.\n",
    "\tos.environ[\"PYTHONHASHSEED\"]=\"0\"\n",
    "\t# The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "\tnp.random.seed(seed)\n",
    "\t# The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "\trn.seed(seed)\n",
    "\t# The below tf.random.set_seed will make x number generation in TensorFlow have a well-defined initial state.\n",
    "\ttf.random.set_seed(seed)     \n",
    "\n",
    "# Definisci le dimensioni delle immagini\n",
    "image_size = 250\n",
    "batch_size = 32\n",
    "\n",
    "# Crea un oggetto ImageDataGenerator per il preprocessing delle immagini\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Carica le immagini dal set di addestramento\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Carica le immagini dal set di test\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Carica le immagini dal set di validazione\n",
    "val_generator = data_generator.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "     \n",
    "\n",
    "def show_training_and_validation_performance(history):\n",
    "\t'''\n",
    "\tshow_training_and_validation_performance is used to plot the performances during the training phase\n",
    "\t:param history: object in which are recorded all the events\n",
    "\t'''\n",
    "\tacc = history.history['accuracy']\n",
    "\tval_acc = history.history['val_accuracy']\n",
    "\tloss = history.history['loss']\n",
    "\tval_loss = history.history['val_loss']\n",
    "\n",
    "\tepochs = range(len(acc))\n",
    "\n",
    "\tplt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "\tplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "\tplt.title('Training and validation accuracy')\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.figure()\n",
    "\n",
    "\tplt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "\tplt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "\tplt.title('Training and validation loss')\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.show()\n",
    "\n",
    "def compile_model (model, optimizer='adam', learning_rate = 0.001):\n",
    "\t'''\n",
    "\tcompile_model is used to compile the current model\n",
    "\t:param model: model to compile\n",
    "\t:param optimizer: optimizer to be used\n",
    "\t:param learning_rate: learning rate parameter for the optimizer\n",
    "\t'''\n",
    "\tif optimizer == 'adam':\n",
    "\t\tmodel.compile(loss=\"binary_crossentropy\",\n",
    "\t\toptimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "\t\tmetrics=[\"accuracy\"])\n",
    "\telif optimizer == 'rmsprop':\n",
    "\t\tmodel.compile(loss=\"binary_crossentropy\",\n",
    "\t\t\t\t\toptimizer = optimizers.RMSprop(learning_rate=learning_rate),\n",
    "\t\t\t\t\tmetrics=['accuracy'])\n",
    "\tmodel.summary()\n",
    "\n",
    "def run_model (model, model_name, epochs = 10, patience=5, monitor='val_loss'):\n",
    "\t'''\n",
    "\trun_model is used to run the current mode\n",
    "\t:param model: model to run\n",
    "\t:param model_name: name given to save the model\n",
    "\t:param epochs: how many epochs to do\n",
    "\t:param patience: patience value for Early Stopping\n",
    "\t:param monitor: what to monitor for Early Stopping and Model Checkpoint\n",
    "\t'''\n",
    "\t# local save path for the models\n",
    "\tsave_path = dataset_path + '/' + model_name + '.h5'\n",
    "\tcallbacks_list = [\n",
    "\t\t\t\t\tkeras.callbacks.EarlyStopping(monitor=monitor, patience=patience),\n",
    "\t\t\t\t\tkeras.callbacks.ModelCheckpoint(\n",
    "\t\t\t\t\t\tfilepath = save_path,\n",
    "\t\t\t\t\t\tmonitor=monitor,\n",
    "\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\tsave_best_only=True)\n",
    "\t\t\t\t\t]\n",
    "\thistory = model.fit(train_dataset,\n",
    "\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\tvalidation_data=validation_dataset,\n",
    "\t\t\t\t\t\tcallbacks=callbacks_list)\n",
    "\t# save on Drive only the best model\n",
    "\tshutil.copy(save_path, dataset_path + '/' + model_name + '.h5')\n",
    "\tshow_training_and_validation_performance(history)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from itertools import cycle\n",
    "\n",
    "def plot_roc_curve(y_test, y_pred):\n",
    "\t'''\n",
    "\tplot_roc_curve is used to plot the ROC curve\n",
    "\t:param y_test: true labels\n",
    "\t:param y_pred: predicted labels\n",
    "\t'''\n",
    "\tlabels = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "\tfpr = dict()\n",
    "\ttpr = dict()\n",
    "\troc_auc = dict()\n",
    "\tfor i in range(4):\n",
    "\t\tfpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "\t\troc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "\n",
    "\tcolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green'])\n",
    "\tfor i, color in zip(range(4), colors):\n",
    "\t\tplt.plot(\n",
    "\t\t\tfpr[i],\n",
    "\t\t\ttpr[i],\n",
    "\t\t\tcolor=color,\n",
    "\t\t\tlw=2,\n",
    "\t\t\tlabel='ROC curve of class {0} (area = {1:0.2f})'.format(labels[i], roc_auc[i]),\n",
    "\t\t)\n",
    "\n",
    "\tplt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\tplt.xlim([0.0, 1.0])\n",
    "\tplt.ylim([0.0, 1.05])\n",
    "\tplt.xlabel('False Positive Rate')\n",
    "\tplt.ylabel('True Positive Rate')\n",
    "\tplt.title('Some extension of Receiver operating characteristic to multiclass')\n",
    "\tplt.legend(loc='lower right')\n",
    "\tplt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def evaluate_model (model, test_dataset):\n",
    "\t'''\n",
    "\tevaluate_model is used to plot some statistics about the performance on the test set\n",
    "\t:param model: model to consider\n",
    "\t'''\n",
    "\tlabels_d= ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "\ty_score = model.predict(test_dataset)\n",
    "\ty_pred = np.rint(y_score) # to have 0 or 1\n",
    "\ty_true = tf.concat([labels_batch for data_batch, labels_batch in test_dataset], axis = 0)\n",
    "\tprint(\"Classification report: \")\n",
    "\tprint(metrics.classification_report(y_true,y_pred,digits = 4))\n",
    "\tmetrics.ConfusionMatrixDisplay.from_predictions(y_true, y_pred,labels=labels_d)\n",
    "\tplot_roc_curve(y_true,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "# Carica il modello VGG16 pre-addestrato, senza l'ultimo strato fully connected\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(250, 250, 3))\n",
    "\n",
    "# Aggiungi un nuovo strato fully connected all'ultimo layer di VGG16\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax')) #4 classi di output\n",
    "\n",
    "# Congela i pesi del modello base, cos√¨ da mantenere l'informazione appresa\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compila il modello\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Addestra il modello\n",
    "history = model.fit(train_generator, batch_size=32, epochs=10, validation_data=(val_generator))\n",
    "\n",
    "# Valuta il modello\n",
    "test_loss, test_acc = model.evaluate(test_generator, batch_size=32)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
